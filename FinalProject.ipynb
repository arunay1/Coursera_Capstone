{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a><img src = \"barbecue-bbq-dinner-111131.jpg\" width =600, height = 100 align = \"center\"></a>\n",
    "\n",
    "\n",
    "<h1 align=center><font size = 5 color = brown>Predicting Cuisines having Maximum Potential in a Neighbourhood Restaurant</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents <a name=\"ToC\"></a>\n",
    "* [Business Problem](#introduction)\n",
    "* [Description of Data](#data)\n",
    "* [Methodology](#methodology)\n",
    "* [Analysis of Results and Discussion](#results)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = brown><i> Business Problem</font></i> <a name=\"introduction\"></a>\n",
    "<font face=calibri size=3>The objective of this report is to help anyone who intends to set up a restaurant or eatery in a neighborhood decide on where and what type of cuisines to serve through analysis of data sourced from foursquare and US census bureau. \n",
    "<br/><br/>\n",
    "“Explore where one should open a restaurant and what type of cuisine to serve through use of data analytics and Machine Learning”.\n",
    "<br/><br/>\n",
    "One business strategy coule be to explore cuisine which is not served in the neighbourhood abother could be venture into cuisne mostly served in the area.\n",
    "\n",
    "</font>\n",
    "[Back To ToC](#ToC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = brown><i>  Description of Data</i></font> <a name=\"data\"></a>\n",
    "<font face=calibri size=3>\n",
    "For this project I intend to use data gathered from foursquare about type of cuisine most served at a neighbourhood and US census portal about neighbourhood profile through use of API’s. \n",
    "<br/><br/>\n",
    "I will focus on using supervised learning algorithms classify data points into categorical type of cuisine using best classification model\n",
    "<br/><br/>\n",
    "US Census has API’s which provide information about geographies for more than 18000 variables. I plan to use variables pertaining to age, race, income etc. along with data obtained from foursquare regarding number of place, type of cuisine and then predict the type of cuisine can be served when setting a restaurant in a new neighborhood.\n",
    "\n",
    "Based on definition of our problem, factors that will influence our decission are:\n",
    "* number of existing restaurants in the neighborhood (any type of restaurant)\n",
    "* Demographic profile of the neighborhood\n",
    "\n",
    "Based on center of location I plan to get number of existing restaurants in the neighborhood in a radius of 25 or 50km and then take them as target variable based on Demographic profile.\n",
    "\n",
    "Following data sources will be needed to extract/generate the required information:\n",
    "* centers of candidate areas will be generated algorithmically and approximate addresses of centers of those areas will be obtained using **Google Maps API reverse geocoding**\n",
    "* number of restaurants for each cuisine type in neighborhood i.e approximate radius of <25 km> will be obtained using **Foursquare API**\n",
    "* Demographic profile of the neighborhood will be obtained using **US Census API**\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "[Back To ToC](#ToC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = brown><i>  Methodology</i> </font> <a name=\"methodology\"></a>\n",
    "\n",
    "<font face=calibri size=3>\n",
    "To predicit best type of cuisine to serve in a neighbourhood I followed following series of Step.\n",
    "\n",
    "* Finding Demograhich profile of all US regions defined by the US Census. I would be using Income, Age and work related variables. Description of these variables is defined in US census(The list of variables I have used is given in file projParams.py. I have taken variables for Male/Femal Age, Education profile and Income distribution profile. \n",
    "<br><br>\n",
    "\n",
    "* Downling longitude and latitude of all these locations using google API. Since foursquare API allows only 950 free calls only per day so I have taken only 1400 locations. \n",
    "<br><br>\n",
    "\n",
    "* Getting count of restaurants and cuisine served in all the regions. Then finding the topmost cuisine served in the regions.   This topmost resturant cusisine type becomes my target variable for prediction using classification models.\n",
    "\n",
    "<br>\n",
    "* Once I have predicted cuisine type corrected I would be using regression to predict count of restaurants each region can support. With count of exisiting restaurants  we got from fourSquare I will find difference of predicted count. The regions where the difference is maximum I can conclude that is the best location for setting the Restaurant with maximum potential.\n",
    "\n",
    "[Back To ToC](#ToC)\n",
    "#### Getting all the required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reauired Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "#!pip install census   \n",
    "#!pip install us    \n",
    "#!pip install geopy\n",
    "\n",
    "import json                               # library to handle JSON files\n",
    "import time                               # library for timing a script\n",
    "import numpy                   as np      # library to handle data in a vectorized manner\n",
    "import pickle\n",
    "import pandas                  as pd      # library for data analsysis\n",
    "import requests                           # library to handle requests\n",
    "\n",
    "import operator                           # library for Mathematial Operators\n",
    "import importlib\n",
    "\n",
    "from bs4            import BeautifulSoup  # library for parsing the html page\n",
    "from time           import sleep          # \n",
    "from pandas.io.json import json_normalize # library to tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "%matplotlib inline\n",
    "import matplotlib.cm     as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Reauired Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Importing Project specific Constants, Lists and API Keys\n",
    "import projParams as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from census import Census\n",
    "from us     import states\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"DataScieneProject\")\n",
    "c = Census(config.projectSecrets['clientAPIKey'],year=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCoordinatesFromGoogle(api_key, address, verbose=False):\n",
    "    try:\n",
    "        url = 'https://maps.googleapis.com/maps/api/geocode/json?key={}&address={}'.format(api_key, address)\n",
    "        response = requests.get(url).json()\n",
    "        if verbose:\n",
    "            print('Google Maps API JSON result =>', response)\n",
    "        results = response['results']\n",
    "        geographical_data = results[0]['geometry']['location'] # get geographical coordinates\n",
    "        lat = geographical_data['lat']\n",
    "        lon = geographical_data['lng']\n",
    "        return [lat, lon]\n",
    "    except:\n",
    "        return [None, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = brown><i>  Getting Supporting Data </i> </font> <a name=\"places\"></a>\n",
    "\n",
    "<font face=calibri size=3>\n",
    "<br>\n",
    "[Back To ToC](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US Mainland States for which this study is limited to = 51 \n",
      "Total Number of Geographic Area captured by US Census = 43934 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SummaryLevel</th>\n",
       "      <th>StateCode_FIPS</th>\n",
       "      <th>County_Code_FIPS</th>\n",
       "      <th>County_Subdivision_Code_FIPS</th>\n",
       "      <th>Place_Code_FIPS</th>\n",
       "      <th>Consolidtated_City_Code_FIPS</th>\n",
       "      <th>Area_Name</th>\n",
       "      <th>stateName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SummaryLevel  StateCode_FIPS  County_Code_FIPS  \\\n",
       "0            40               1                 0   \n",
       "1            50               1                 1   \n",
       "2            50               1                 3   \n",
       "3            50               1                 5   \n",
       "4            50               1                 7   \n",
       "\n",
       "   County_Subdivision_Code_FIPS  Place_Code_FIPS  \\\n",
       "0                             0                0   \n",
       "1                             0                0   \n",
       "2                             0                0   \n",
       "3                             0                0   \n",
       "4                             0                0   \n",
       "\n",
       "   Consolidtated_City_Code_FIPS       Area_Name stateName  \n",
       "0                             0         Alabama   Alabama  \n",
       "1                             0  Autauga County   Alabama  \n",
       "2                             0  Baldwin County   Alabama  \n",
       "3                             0  Barbour County   Alabama  \n",
       "4                             0     Bibb County   Alabama  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USMainLandStatesDF = pd.read_csv(\"usMainLandStates.csv\")\n",
    "USMainLandStatesDF.state = USMainLandStatesDF.state.astype(int)\n",
    "print('US Mainland States for which this study is limited to = {} '.format(USMainLandStatesDF.shape[0]) )\n",
    "\n",
    "### https://www.census.gov/geographies/reference-files/2016/demo/popest/2016-fips.html\n",
    "### File downloaded from above link is formatted and converted into excel for reading by pandas\n",
    "### \n",
    "allGeoCodesDF = pd.read_csv(\"allGeoCodes.csv\")\n",
    "print('Total Number of Geographic Area captured by US Census = {} '.format(allGeoCodesDF.shape[0]) )\n",
    "\n",
    "allGeoCodesDF = pd.merge(allGeoCodesDF,\n",
    "                         USMainLandStatesDF.loc[:, ['state','stateName']],\n",
    "                         left_on =['StateCode_FIPS'] , \n",
    "                         right_on=['state'])\n",
    "\n",
    "allGeoCodesDF.drop('state', 1, inplace=True)\n",
    "allGeoCodesDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = brown><i>  Getting Places Information from US Census Portal</i> </font> <a name=\"places\"></a>\n",
    "\n",
    "<font face=calibri size=3>\n",
    "Places and 'County- SubDivision' are  the smallest level of Geographic region defined the US Census for which demographic information is available. \n",
    "<br>\n",
    "[Back To ToC](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of Place Demographics file                     = True \n",
      "Total Number of Places Demographic profile available  = 19506 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>place</th>\n",
       "      <th>B01001_001E</th>\n",
       "      <th>B01002_001E</th>\n",
       "      <th>B01001_011E</th>\n",
       "      <th>B01001_012E</th>\n",
       "      <th>B01001_013E</th>\n",
       "      <th>B01001_014E</th>\n",
       "      <th>B01001_015E</th>\n",
       "      <th>B01001_016E</th>\n",
       "      <th>...</th>\n",
       "      <th>B19001_017E</th>\n",
       "      <th>B23022_003E</th>\n",
       "      <th>B23022_027E</th>\n",
       "      <th>B25008_003E</th>\n",
       "      <th>B25031_001E</th>\n",
       "      <th>B25077_001E</th>\n",
       "      <th>county</th>\n",
       "      <th>county subdivision</th>\n",
       "      <th>stateName</th>\n",
       "      <th>Area_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>2594.0</td>\n",
       "      <td>44.9</td>\n",
       "      <td>113.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>543.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>553.0</td>\n",
       "      <td>80200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Abbeville city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>4404.0</td>\n",
       "      <td>42.7</td>\n",
       "      <td>63.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>97100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>484</td>\n",
       "      <td>725.0</td>\n",
       "      <td>47.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>75100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Addison town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>676</td>\n",
       "      <td>318.0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>38800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Akron town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>820</td>\n",
       "      <td>32567.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>1252.0</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>...</td>\n",
       "      <td>293.0</td>\n",
       "      <td>8958.0</td>\n",
       "      <td>7285.0</td>\n",
       "      <td>5648.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>167800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabaster city</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  place  B01001_001E  B01002_001E  B01001_011E  B01001_012E  \\\n",
       "0      1    124       2594.0         44.9        113.0        106.0   \n",
       "1      1    460       4404.0         42.7         63.0        106.0   \n",
       "2      1    484        725.0         47.6         14.0         27.0   \n",
       "3      1    676        318.0         40.3          0.0         10.0   \n",
       "4      1    820      32567.0         37.0        593.0        990.0   \n",
       "\n",
       "   B01001_013E  B01001_014E  B01001_015E  B01001_016E       ...         \\\n",
       "0         58.0         69.0         40.0        105.0       ...          \n",
       "1        200.0        136.0         90.0        147.0       ...          \n",
       "2         19.0         19.0         36.0         23.0       ...          \n",
       "3          5.0          4.0          3.0         24.0       ...          \n",
       "4       1274.0       1326.0       1252.0       1404.0       ...          \n",
       "\n",
       "   B19001_017E  B23022_003E  B23022_027E  B25008_003E  B25031_001E  \\\n",
       "0         21.0        543.0        384.0        771.0        553.0   \n",
       "1         14.0        928.0        903.0       1083.0        862.0   \n",
       "2          0.0        185.0        108.0        221.0        356.0   \n",
       "3          0.0         48.0         55.0        114.0        533.0   \n",
       "4        293.0       8958.0       7285.0       5648.0        983.0   \n",
       "\n",
       "   B25077_001E  county  county subdivision  stateName        Area_Name  \n",
       "0      80200.0       0                   0    Alabama   Abbeville city  \n",
       "1      97100.0       0                   0    Alabama  Adamsville city  \n",
       "2      75100.0       0                   0    Alabama     Addison town  \n",
       "3      38800.0       0                   0    Alabama       Akron town  \n",
       "4     167800.0       0                   0    Alabama   Alabaster city  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPlaceDemographics():\n",
    "    a = c.acs5.get('B01001_001E', {'for': 'place:*'})\n",
    "    placeDemoDF = pd.DataFrame(a)\n",
    "    placeDemoDF.set_index(['state', 'place'], inplace=True)  \n",
    "    \n",
    "    for name in varList:\n",
    "        if (varList[name] != 'B01001_001E'):\n",
    "            tempList = c.acs5.get(varList[name], {'for': 'place:*'})\n",
    "            tempDF   = pd.DataFrame(tempList) \n",
    "            tempDF.set_index(['state', 'place'], inplace=True)                \n",
    "            placeDemoDF = pd.merge(placeDemoDF, tempDF, left_index=True, right_index=True)\n",
    "            print(' .', end='')        \n",
    "    print(' Done', end='')  \n",
    "        \n",
    "    # persisting to local drive for repeated runs/use\n",
    "    placeDemoDF['county']=0\n",
    "    placeDemoDF['county subdivision']=0\n",
    "\n",
    "    placeDemoDF = pd.merge(placeDemoDF,\n",
    "                           allGeoCodesDF.loc[(allGeoCodesDF[\"County_Code_FIPS\"]             ==0) &\n",
    "                                             (allGeoCodesDF[\"County_Subdivision_Code_FIPS\"] ==0) &\n",
    "                                             (allGeoCodesDF[\"Place_Code_FIPS\"]              > 0),['StateCode_FIPS','Place_Code_FIPS','stateName','Area_Name']],\n",
    "                           left_on =['state'         ,'place'] , \n",
    "                           right_on=['StateCode_FIPS','Place_Code_FIPS'])\n",
    "\n",
    "    placeDemoDF.drop('StateCode_FIPS', 1, inplace=True)\n",
    "    placeDemoDF.drop('Place_Code_FIPS',1, inplace=True)    \n",
    "    placeDemoDF.to_csv(\"placeDemoDF.csv\", index=True)\n",
    "\n",
    "    return placeDemoDF\n",
    "\n",
    "loaded = False\n",
    "try:\n",
    "    placeDemoDF = pd.read_csv(\"placeDemoDF.csv\", encoding=\"cp1252\", dtype= config.varListTypes)\n",
    "    loaded = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print('Status of Place Demographics file                     = {} '.format(loaded) )\n",
    "# If load failed then call US Census and populate variables \n",
    "if not loaded:    \n",
    "    placeDemoDF = getPlaceDemographics()    \n",
    "print('Total Number of Places Demographic profile available  = {} '.format(placeDemoDF.shape[0]) )\n",
    "\n",
    "placeDemoDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = brown><i>  Getting County - SubDivision Information from US Census Portal</i> </font> <a name=\"subdiv\"></a>\n",
    "<font face=calibri size=3>\n",
    "Places and 'County- SubDivision' are  the smallest level of Geographic region defined the US Census for which demographic information is available. \n",
    "<br>\n",
    "[Back To ToC](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of County Sub Div Demographics file            = True \n",
      "Total Numbe of County Sub Div Demographics available  = 21137 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>county subdivision</th>\n",
       "      <th>B01001_001E</th>\n",
       "      <th>B01002_001E</th>\n",
       "      <th>B01001_011E</th>\n",
       "      <th>B01001_012E</th>\n",
       "      <th>B01001_013E</th>\n",
       "      <th>B01001_014E</th>\n",
       "      <th>B01001_015E</th>\n",
       "      <th>...</th>\n",
       "      <th>B19001_016E</th>\n",
       "      <th>B19001_017E</th>\n",
       "      <th>B23022_003E</th>\n",
       "      <th>B23022_027E</th>\n",
       "      <th>B25008_003E</th>\n",
       "      <th>B25031_001E</th>\n",
       "      <th>B25077_001E</th>\n",
       "      <th>place</th>\n",
       "      <th>stateName</th>\n",
       "      <th>Area_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>63480</td>\n",
       "      <td>9274.0</td>\n",
       "      <td>47.1</td>\n",
       "      <td>141.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>...</td>\n",
       "      <td>474.0</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>2162.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>597500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Redding town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>74190</td>\n",
       "      <td>52529.0</td>\n",
       "      <td>44.1</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>13189.0</td>\n",
       "      <td>13763.0</td>\n",
       "      <td>9039.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>250700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Stratford town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>73070</td>\n",
       "      <td>128851.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6045.0</td>\n",
       "      <td>5291.0</td>\n",
       "      <td>4973.0</td>\n",
       "      <td>4239.0</td>\n",
       "      <td>4699.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4366.0</td>\n",
       "      <td>9319.0</td>\n",
       "      <td>38568.0</td>\n",
       "      <td>33626.0</td>\n",
       "      <td>57359.0</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>516000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Stamford town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>50580</td>\n",
       "      <td>20357.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>162.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>...</td>\n",
       "      <td>730.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>4686.0</td>\n",
       "      <td>3658.0</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>1439600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>New Canaan town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>50860</td>\n",
       "      <td>14091.0</td>\n",
       "      <td>45.1</td>\n",
       "      <td>293.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>...</td>\n",
       "      <td>647.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>3830.0</td>\n",
       "      <td>3631.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>356600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>New Fairfield town</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  county  county subdivision  B01001_001E  B01002_001E  B01001_011E  \\\n",
       "0      9       1               63480       9274.0         47.1        141.0   \n",
       "1      9       1               74190      52529.0         44.1       1438.0   \n",
       "2      9       1               73070     128851.0         37.0       6045.0   \n",
       "3      9       1               50580      20357.0         43.2        162.0   \n",
       "4      9       1               50860      14091.0         45.1        293.0   \n",
       "\n",
       "   B01001_012E  B01001_013E  B01001_014E  B01001_015E         ...          \\\n",
       "0        257.0        103.0        143.0        464.0         ...           \n",
       "1       1394.0       1468.0       1561.0       1865.0         ...           \n",
       "2       5291.0       4973.0       4239.0       4699.0         ...           \n",
       "3         92.0        658.0        591.0        854.0         ...           \n",
       "4        259.0        355.0        365.0        627.0         ...           \n",
       "\n",
       "   B19001_016E  B19001_017E  B23022_003E  B23022_027E  B25008_003E  \\\n",
       "0        474.0       1084.0       2376.0       2162.0       1346.0   \n",
       "1       1894.0       1438.0      13189.0      13763.0       9039.0   \n",
       "2       4366.0       9319.0      38568.0      33626.0      57359.0   \n",
       "3        730.0       3140.0       4686.0       3658.0       3679.0   \n",
       "4        647.0        743.0       3830.0       3631.0        934.0   \n",
       "\n",
       "   B25031_001E  B25077_001E  place    stateName           Area_Name  \n",
       "0       1586.0     597500.0      0  Connecticut        Redding town  \n",
       "1       1224.0     250700.0      0  Connecticut      Stratford town  \n",
       "2       1704.0     516000.0      0  Connecticut       Stamford town  \n",
       "3       2001.0    1439600.0      0  Connecticut     New Canaan town  \n",
       "4       2180.0     356600.0      0  Connecticut  New Fairfield town  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getCountySubdivDemographics():\n",
    "    USMainLandStatesList = list(USMainLandStatesDF.state)\n",
    "    stateCountySubdivDF = pd.DataFrame(columns=config.stateCountySubdivCols)\n",
    "\n",
    "    for st in USMainLandStatesList:\n",
    "        st= str(st).zfill(2)\n",
    "        print('Included State : {}  Variable :{} '.format(st , 'B01001_001E')) \n",
    "        b = c.acs5.get('B01001_001E', {'for': 'county subdivision:*', 'in': 'state:'+ st }  )\n",
    "        countySubdivDF = pd.DataFrame(b)\n",
    "        countySubdivDF.set_index(['state', 'county','county subdivision'], inplace=True)\n",
    "        \n",
    "        for name in varList:\n",
    "            if (varList[name] !='B01001_001E'):\n",
    "                print('Included State : {}  Variable :{} '.format(st , varList[name])) \n",
    "                tempList = c.acs5.get(varList[name], {'for': 'county subdivision:*', 'in': 'state:'+ st})\n",
    "                tempDF   = pd.DataFrame(tempList)\n",
    "                tempDF.set_index(['state', 'county','county subdivision'], inplace=True)                \n",
    "                countySubdivDF = pd.merge(countySubdivDF, tempDF, left_index=True, right_index=True)\n",
    "                print(' .', end='')\n",
    "    \n",
    "    stateCountySubdivDF =  stateCountySubdivDF.append(countySubdivDF)\n",
    "    print(' Done', end='') \n",
    "\n",
    "    ### \n",
    "    stateCountySubdivDF['place']=0    \n",
    "    stateCountySubdivDF = pd.merge(stateCountySubdivDF,\n",
    "                 allGeoCodesDF.loc[(allGeoCodesDF[\"County_Code_FIPS\"]             > 0) &\n",
    "                                   (allGeoCodesDF[\"County_Subdivision_Code_FIPS\"] > 0) &\n",
    "                                   (allGeoCodesDF[\"Place_Code_FIPS\"]              ==0 ),['StateCode_FIPS','County_Code_FIPS','County_Subdivision_Code_FIPS','stateName','Area_Name']],\n",
    "                           left_on =['state'         ,'county'          ,'county subdivision'] , \n",
    "                           right_on=['StateCode_FIPS','County_Code_FIPS','County_Subdivision_Code_FIPS'])\n",
    "\n",
    "    stateCountySubdivDF.drop('StateCode_FIPS', 1, inplace=True)\n",
    "    stateCountySubdivDF.drop('County_Code_FIPS',1, inplace=True)\n",
    "    stateCountySubdivDF.drop('County_Subdivision_Code_FIPS',1, inplace=True)\n",
    "    \n",
    "    return stateCountySubdivDF\n",
    "    # persisting to local drive for repeated runs/use\n",
    "    stateCountySubdivDF.to_csv(\"stateCountySubdivDF.csv\")\n",
    "\n",
    "loaded = False\n",
    "try:\n",
    "    stateCountySubdivDF = pd.read_csv(\"stateCountySubdivDF.csv\", encoding=\"cp1252\", dtype= config.varListTypes)\n",
    "    loaded = True\n",
    "except:\n",
    "    pass\n",
    "     \n",
    "print('Status of County Sub Div Demographics file            = {} '.format(loaded) )    \n",
    "# If load failed then call US Census and populate variables \n",
    "if not loaded:    \n",
    "    stateCountySubdivDF = getCountySubdivDemographics()\n",
    "print('Total Numbe of County Sub Div Demographics available  = {} '.format(stateCountySubdivDF.shape[0] ) )\n",
    "stateCountySubdivDF.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = brown><i> Creating Places of Interest </i> </font> <a name=\"locations\"></a>\n",
    "<font face=calibri size=3>\n",
    "\n",
    "I will be merging 'places' dataframe and 'County-SubDivision' dataframe in a single dataframe as Locations of interest. \n",
    "\n",
    "For each of these locations of interest I will be finding the count of different type of cuisines served in a restaurant. \n",
    "\n",
    "I have grouped various type of restaurant by their category into broad 12 cuisines types (https://en.wikipedia.org/wiki/List_of_cuisines) of the World based. Although this may be debatable and may not be accurate but for purpose of this report I am not diving deeper into this.\n",
    "\n",
    "If a cuisine type has very sub-catregories I have merged it to top leval or cuisine of region closest to its region. \n",
    "\n",
    "<br>\n",
    "[Back To ToC](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of County-Sub Div from US Census.........= 21137 \n",
      "Total Places of Interest from US Census...............= 19506 \n",
      "Total Number of Places of Interest for evaluation.....= 40643 \n"
     ]
    }
   ],
   "source": [
    "locationsDF = placeDemoDF.append(stateCountySubdivDF)\n",
    "locationsDF['locationsName'] = locationsDF['Area_Name']+', '+ locationsDF['stateName'] + ', USA'\n",
    "locationsDF.to_csv(\"locationsDF.csv\", index=False) \n",
    "\n",
    "print('Total Number of County-Sub Div from US Census.........= {} '.format(stateCountySubdivDF.shape[0] ) )\n",
    "print('Total Places of Interest from US Census...............= {} '.format(placeDemoDF.shape[0] ) )\n",
    "print('Total Number of Places of Interest for evaluation.....= {} '.format(locationsDF.shape[0] ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = brown><i> Getting Geographic Co-ordinates of places of Interest </i> </font> <a name=\"geolocations\"></a>\n",
    "<font face=calibri size=3>\n",
    "\n",
    "<br>\n",
    "[Back To ToC](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is sampled Places of Interest file available..........= True \n",
      "Tot Num of Sampled Geo-Coordinated Places of Interest.= 1409 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area_Name</th>\n",
       "      <th>B01001_001E</th>\n",
       "      <th>B01001_011E</th>\n",
       "      <th>B01001_012E</th>\n",
       "      <th>B01001_013E</th>\n",
       "      <th>B01001_014E</th>\n",
       "      <th>B01001_015E</th>\n",
       "      <th>B01001_016E</th>\n",
       "      <th>B01001_017E</th>\n",
       "      <th>B01001_018E</th>\n",
       "      <th>...</th>\n",
       "      <th>B25031_001E</th>\n",
       "      <th>B25077_001E</th>\n",
       "      <th>county</th>\n",
       "      <th>county subdivision</th>\n",
       "      <th>place</th>\n",
       "      <th>state</th>\n",
       "      <th>stateName</th>\n",
       "      <th>locationsName</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brownsville borough</td>\n",
       "      <td>2181.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>544.0</td>\n",
       "      <td>58200.0</td>\n",
       "      <td>51</td>\n",
       "      <td>9432</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Brownsville borough, Pennsylvania, USA</td>\n",
       "      <td>40.023685</td>\n",
       "      <td>-79.883936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jackson township</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>707.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>111</td>\n",
       "      <td>34825</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>Jackson township, Kansas, USA</td>\n",
       "      <td>39.032697</td>\n",
       "      <td>-96.556988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dinosaur town</td>\n",
       "      <td>315.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>821.0</td>\n",
       "      <td>101900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20495</td>\n",
       "      <td>8</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Dinosaur town, Colorado, USA</td>\n",
       "      <td>40.243578</td>\n",
       "      <td>-109.014561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hobgood town</td>\n",
       "      <td>353.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>748.0</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31860</td>\n",
       "      <td>37</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Hobgood town, North Carolina, USA</td>\n",
       "      <td>36.029879</td>\n",
       "      <td>-77.397746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marceline city</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>486.0</td>\n",
       "      <td>60800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45866</td>\n",
       "      <td>29</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Marceline city, Missouri, USA</td>\n",
       "      <td>39.711970</td>\n",
       "      <td>-92.948253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Area_Name  B01001_001E  B01001_011E  B01001_012E  B01001_013E  \\\n",
       "0  Brownsville borough       2181.0         46.0         60.0        111.0   \n",
       "1     Jackson township       1044.0         10.0         27.0         13.0   \n",
       "2        Dinosaur town        315.0         30.0         21.0         20.0   \n",
       "3         Hobgood town        353.0         13.0         13.0          7.0   \n",
       "4       Marceline city       2107.0         40.0         53.0        100.0   \n",
       "\n",
       "   B01001_014E  B01001_015E  B01001_016E  B01001_017E  B01001_018E  \\\n",
       "0         43.0         90.0         59.0         72.0         62.0   \n",
       "1         35.0         26.0         48.0         45.0          1.0   \n",
       "2          2.0          5.0         13.0          2.0         12.0   \n",
       "3          4.0         17.0         22.0         19.0          6.0   \n",
       "4         56.0         37.0         75.0         56.0         36.0   \n",
       "\n",
       "      ...      B25031_001E  B25077_001E  county  county subdivision  place  \\\n",
       "0     ...            544.0      58200.0      51                9432      0   \n",
       "1     ...            707.0     112500.0     111               34825      0   \n",
       "2     ...            821.0     101900.0       0                   0  20495   \n",
       "3     ...            748.0      59000.0       0                   0  31860   \n",
       "4     ...            486.0      60800.0       0                   0  45866   \n",
       "\n",
       "   state       stateName                           locationsName        lat  \\\n",
       "0     42    Pennsylvania  Brownsville borough, Pennsylvania, USA  40.023685   \n",
       "1     20          Kansas           Jackson township, Kansas, USA  39.032697   \n",
       "2      8        Colorado            Dinosaur town, Colorado, USA  40.243578   \n",
       "3     37  North Carolina       Hobgood town, North Carolina, USA  36.029879   \n",
       "4     29        Missouri           Marceline city, Missouri, USA  39.711970   \n",
       "\n",
       "         long  \n",
       "0  -79.883936  \n",
       "1  -96.556988  \n",
       "2 -109.014561  \n",
       "3  -77.397746  \n",
       "4  -92.948253  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getLocationCoordinates(locationNamesList):\n",
    "    counter      = 0\n",
    "    step         = 1000\n",
    "    placeGeoCord = []\n",
    "    dfSize       = len(locationNamesList)\n",
    "    while counter < dfSize :\n",
    "        if (counter + step < dfSize ):\n",
    "            batch = locationNamesList[counter:counter+step]        \n",
    "        else:\n",
    "            batch = locationNamesList[counter:]\n",
    "        counter = counter + step\n",
    "\n",
    "        batchCoord = [getCoordinatesFromGoogle(config.projectSecrets['googleAPIkey'], x) for x in batch]\n",
    "        placeGeoCord = placeGeoCord + batchCoord\n",
    "\n",
    "        print(' .', end='')\n",
    "    print(' Done')\n",
    "    return placeGeoCord\n",
    "    \n",
    "loaded = False\n",
    "try:\n",
    "    locationsSampleDF = pd.read_csv(\"locationsSampleDF.csv\", encoding=\"cp1252\", dtype= config.varListTypes)\n",
    "    loaded = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print('Is sampled Places of Interest file available..........= {} '.format(loaded ))\n",
    "\n",
    "## If load failed then calling google API's and getting data only for sample of 20% of Locations Data\n",
    "## which is about 8,000 records.\n",
    "##\n",
    "if not loaded:\n",
    "    locationsSampleDF = locationsDF.sample(frac = 0.20 )    \n",
    "    placeGeoCord = getLocationCoordinates( list(locationsSampleDF['locationsName']) )\n",
    "    \n",
    "    locationsSampleDF['lat'] = [x[0] for x in placeGeoCord]\n",
    "    locationsSampleDF['long']= [x[1] for x in placeGeoCord]\n",
    "    \n",
    "    # persisting to local drive for repeated runs/use\n",
    "    locationsSampleDF.to_csv(\"locationsSampleDF.csv\", index=False)\n",
    "\n",
    "locationsSampleDF = locationsSampleDF[locationsSampleDF['long'].notnull()]\n",
    "\n",
    "print('Tot Num of Sampled Geo-Coordinated Places of Interest.= {} '.format(locationsSampleDF.shape[0] ) )  \n",
    "locationsSampleDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foursquare\n",
    "Foursquare categorizes reastaurancts and places on basis of type of cuisine it serves. Based on geographical region restaurancts can be classifed in to broad place of origin.\n",
    "\n",
    "For this project I am only interest in venues in 'food category' I will use FourSquare to get predominant cusinene served in the neighbourhood restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPreferredCuisine(venues, rank):\n",
    "    locationCuisineCount = {'eastAsianCuisine'       : 0,\n",
    "                            'southAsianCuisine'      : 0,\n",
    "                            'southEastAsianCuisine'  : 0,\n",
    "                            'westAsianCuisine'       : 0,\n",
    "                            'africanCuisine'         : 0,\n",
    "                            'centralEuroCuisine'     : 0,\n",
    "                            'eastNorthernEuroCuisine': 0,\n",
    "                            'southernEuroCuisine'    : 0,\n",
    "                            'westernEuroCuisine'     : 0,\n",
    "                            'northAmericanCuisine'   : 0,\n",
    "                            'southAmericanCuisine'   : 0,\n",
    "                            'caribbeanCuisine'       : 0,\n",
    "                            'Others':0}    \n",
    "    for venue in venues:\n",
    "        locationCuisineCount[venue[1]] = (locationCuisineCount[venue[1]] +1)\n",
    "    \n",
    "    ### Removing Others form Dictionary since Others include large number of values in Dataset\n",
    "    if 'Others' in locationCuisineCount.keys():     \n",
    "        locationCuisineCount.pop('Others')\n",
    "\n",
    "    ## Getting cusine which has maximum number of restaurents in a location\n",
    "    sorted_x = sorted(locationCuisineCount.items(), key=operator.itemgetter(1))\n",
    "    \n",
    "    if rank == 1:\n",
    "        preferredCusine      = sorted_x[len(sorted_x)-1][0]\n",
    "        preferredCusineCount = sorted_x[len(sorted_x)-1][1]\n",
    "    if rank == 2:\n",
    "        preferredCusine      = sorted_x[len(sorted_x)-2][0]\n",
    "        preferredCusineCount = sorted_x[len(sorted_x)-2][1]\n",
    "    if rank ==3:\n",
    "        preferredCusine      = sorted_x[len(sorted_x)-3][0]\n",
    "        preferredCusineCount = sorted_x[len(sorted_x)-3][1]\n",
    "\n",
    "    return preferredCusine, preferredCusineCount\n",
    "                \n",
    "def getCatType(categories):\n",
    "    try:\n",
    "        for cat in categories:\n",
    "            category =  config.cuisineType[cat['id']]\n",
    "    except:\n",
    "        category = \"Others\"\n",
    "    return category\n",
    "\n",
    "def parseResults(results):\n",
    "    venues = [(item['venue']['name'],\n",
    "               getCatType(item['venue']['categories']),\n",
    "               item['venue']['location']['distance']) for item in results]\n",
    "    return venues\n",
    "\n",
    "def getVenues(lat, lon):\n",
    "    url = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&ll={},{}&categoryId={}&radius={}&limit={}'.format(config.projectSecrets['4SquareClientID'], config.projectSecrets['4SquareclientSecret'], config.version, lat,  lon, config.food_category , config.radius, config.limit)\n",
    "    try:\n",
    "        results = requests.get(url).json()['response']['groups'][0]['items']\n",
    "    except:\n",
    "        print(\"Err\",end='')\n",
    "        results = None\n",
    "    return  results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Enriched FourSquare file with restaurant Info......= True \n",
      "Total Num of rows in enriched sample file ............= 1394 \n"
     ]
    }
   ],
   "source": [
    "def getLocationStatistics(lat, lon):\n",
    "    counter = 0\n",
    "    start = time.time()\n",
    "    locationStat=[]    \n",
    "    for lat, lon in zip(lat, lon):\n",
    "        results    =  getVenues(lat , lon) \n",
    "        sleep(.5)    ### Introducing time delay of .5 sec, since fourSquare allows 2 API calls per second.\n",
    "        if results is not None:\n",
    "            venues      = parseResults(results) \n",
    "            totalVenues = len(venues)\n",
    "            top1CuisineNM, top1CuisineCnt = getPreferredCuisine(venues, 1)\n",
    "            top2CuisineNM, top2CuisineCnt = getPreferredCuisine(venues, 2)\n",
    "            top3CuisineNM, top3CuisineCnt = getPreferredCuisine(venues, 3)\n",
    "        else:\n",
    "            totalVenues   = most_pop_cuisine_cnt = second_popular_cuisine_count = third_popular_cuisine_count = 0\n",
    "            top1CuisineNM = top2CuisineNM        = top3CuisineNM                = np.nan\n",
    "            \n",
    "        locatStat= {'region_cnt'            : totalVenues,\n",
    "                    'most_pop_cuisine_nm'   : top1CuisineNM, \n",
    "                    'most_pop_cuisine_cnt'  : top1CuisineCnt, \n",
    "                    'second_pop_cuisine_nm' : top2CuisineNM,\n",
    "                    'second_pop_cuisine_cnt': top2CuisineCnt,                      \n",
    "                    'third_pop_cuisine_nm'  : top3CuisineNM,\n",
    "                    'third_pop_cuisine_cnt' : top3CuisineCnt} \n",
    "        locationStat.append(locatStat)\n",
    "        print(' .', end='')\n",
    "    print(' done.')\n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "    return locationStat\n",
    "\n",
    "# First try to load from local file system in case\n",
    "loaded = False\n",
    "try:\n",
    "    locationsSampleStatsDF = pd.read_csv(\"locationsSampleFourSquareStatsDF.csv\", encoding=\"cp1252\", dtype= config.varListTypes)\n",
    "    loaded = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print('Is Enriched FourSquare file with restaurant Info......= {} '.format(loaded ))\n",
    "\n",
    "# If load failed use the Foursquare API to get the data\n",
    "if not loaded:    \n",
    "    lats  = list(locationsSampleDF.lat)\n",
    "    longs = list(locationsSampleDF.long)\n",
    "        \n",
    "    #restStats   = getLocationStatistics(lats, longs)\n",
    "    restStatsDF = pd.DataFrame(restStats)\n",
    "    \n",
    "    locationsSampleStatsDF      = pd.concat([locationsSampleDF,restStatsDF ], axis=1)\n",
    "    \n",
    "    # persisting to local drive for repeated runs/use\n",
    "    locationsSampleStatsDF.to_csv(\"locationsSampleFourSquareStatsDF.csv\", index=False)\n",
    "    \n",
    "print('Total Num of rows in enriched sample file ............= {} '.format(locationsSampleStatsDF.shape[0] ) )          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B01001_001E</th>\n",
       "      <th>B01001_011E</th>\n",
       "      <th>B01001_012E</th>\n",
       "      <th>B01001_013E</th>\n",
       "      <th>B01001_014E</th>\n",
       "      <th>B01001_015E</th>\n",
       "      <th>B01001_016E</th>\n",
       "      <th>B01001_017E</th>\n",
       "      <th>B01001_018E</th>\n",
       "      <th>B01001_019E</th>\n",
       "      <th>...</th>\n",
       "      <th>B25031_001E</th>\n",
       "      <th>B25077_001E</th>\n",
       "      <th>locationsName</th>\n",
       "      <th>most_pop_cuisine_cnt</th>\n",
       "      <th>most_pop_cuisine_nm</th>\n",
       "      <th>region_cnt</th>\n",
       "      <th>second_pop_cuisine_cnt</th>\n",
       "      <th>second_pop_cuisine_nm</th>\n",
       "      <th>third_pop_cuisine_cnt</th>\n",
       "      <th>third_pop_cuisine_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2181.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>544.0</td>\n",
       "      <td>58200.0</td>\n",
       "      <td>Brownsville borough, Pennsylvania, USA</td>\n",
       "      <td>20</td>\n",
       "      <td>northAmericanCuisine</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>southernEuroCuisine</td>\n",
       "      <td>8</td>\n",
       "      <td>eastAsianCuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1044.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>707.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Jackson township, Kansas, USA</td>\n",
       "      <td>13</td>\n",
       "      <td>southAmericanCuisine</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>eastAsianCuisine</td>\n",
       "      <td>7</td>\n",
       "      <td>northAmericanCuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>315.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>821.0</td>\n",
       "      <td>101900.0</td>\n",
       "      <td>Dinosaur town, Colorado, USA</td>\n",
       "      <td>1</td>\n",
       "      <td>southAmericanCuisine</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>northAmericanCuisine</td>\n",
       "      <td>0</td>\n",
       "      <td>caribbeanCuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>353.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>748.0</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>Hobgood town, North Carolina, USA</td>\n",
       "      <td>2</td>\n",
       "      <td>northAmericanCuisine</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>southernEuroCuisine</td>\n",
       "      <td>1</td>\n",
       "      <td>southAmericanCuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2107.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>486.0</td>\n",
       "      <td>60800.0</td>\n",
       "      <td>Marceline city, Missouri, USA</td>\n",
       "      <td>2</td>\n",
       "      <td>northAmericanCuisine</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>southAmericanCuisine</td>\n",
       "      <td>1</td>\n",
       "      <td>eastAsianCuisine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   B01001_001E  B01001_011E  B01001_012E  B01001_013E  B01001_014E  \\\n",
       "0       2181.0         46.0         60.0        111.0         43.0   \n",
       "1       1044.0         10.0         27.0         13.0         35.0   \n",
       "2        315.0         30.0         21.0         20.0          2.0   \n",
       "3        353.0         13.0         13.0          7.0          4.0   \n",
       "4       2107.0         40.0         53.0        100.0         56.0   \n",
       "\n",
       "   B01001_015E  B01001_016E  B01001_017E  B01001_018E  B01001_019E  \\\n",
       "0         90.0         59.0         72.0         62.0         33.0   \n",
       "1         26.0         48.0         45.0          1.0         27.0   \n",
       "2          5.0         13.0          2.0         12.0          0.0   \n",
       "3         17.0         22.0         19.0          6.0          7.0   \n",
       "4         37.0         75.0         56.0         36.0         38.0   \n",
       "\n",
       "           ...           B25031_001E  B25077_001E  \\\n",
       "0          ...                 544.0      58200.0   \n",
       "1          ...                 707.0     112500.0   \n",
       "2          ...                 821.0     101900.0   \n",
       "3          ...                 748.0      59000.0   \n",
       "4          ...                 486.0      60800.0   \n",
       "\n",
       "                            locationsName  most_pop_cuisine_cnt  \\\n",
       "0  Brownsville borough, Pennsylvania, USA                    20   \n",
       "1           Jackson township, Kansas, USA                    13   \n",
       "2            Dinosaur town, Colorado, USA                     1   \n",
       "3       Hobgood town, North Carolina, USA                     2   \n",
       "4           Marceline city, Missouri, USA                     2   \n",
       "\n",
       "    most_pop_cuisine_nm  region_cnt  second_pop_cuisine_cnt  \\\n",
       "0  northAmericanCuisine         100                      11   \n",
       "1  southAmericanCuisine         100                      11   \n",
       "2  southAmericanCuisine           3                       1   \n",
       "3  northAmericanCuisine          34                       2   \n",
       "4  northAmericanCuisine          17                       1   \n",
       "\n",
       "   second_pop_cuisine_nm  third_pop_cuisine_cnt  third_pop_cuisine_nm  \n",
       "0    southernEuroCuisine                      8      eastAsianCuisine  \n",
       "1       eastAsianCuisine                      7  northAmericanCuisine  \n",
       "2   northAmericanCuisine                      0      caribbeanCuisine  \n",
       "3    southernEuroCuisine                      1  southAmericanCuisine  \n",
       "4   southAmericanCuisine                      1      eastAsianCuisine  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locationsSampleStatsDF.drop(['Area_Name','county','county subdivision','place','state','stateName','lat','long'], 1 , inplace=True)\n",
    "locationsSampleStatsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = brown><i> Distribution of Top 3 Cuisine Choices in a Place of Interest </i> </font> \n",
    "\n",
    "<font face=calibri size=3 color='brown'>\n",
    "\n",
    "For Purpose of this Report I would focusing on which alternative cuisine has maximum potential in the place of Interest. \n",
    "\n",
    "* I hypothesize top choice for cuisine will always caters to cuisine which matches traditional cuisine of the Region.\n",
    "\n",
    "* Therefore I would be analysing which alternative cusine will find most acceptance in the region therefore for this purpose I will be focussing on third Most popular Choice. \n",
    "\n",
    "* Further given the presence of restaurnts with specific cusine I would find which alternative cusine has maximum potential in a  region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "northAmericanCuisine     909\n",
      "southAmericanCuisine     280\n",
      "southernEuroCuisine       95\n",
      "caribbeanCuisine          72\n",
      "eastAsianCuisine          34\n",
      "southEastAsianCuisine      2\n",
      "centralEuroCuisine         1\n",
      "southAsianCuisine          1\n",
      "Name: most_pop_cuisine_nm, dtype: int64\n",
      "\n",
      "southAmericanCuisine     507\n",
      "northAmericanCuisine     269\n",
      "eastAsianCuisine         259\n",
      "southernEuroCuisine      203\n",
      "caribbeanCuisine         143\n",
      "centralEuroCuisine         6\n",
      "southEastAsianCuisine      3\n",
      "westernEuroCuisine         3\n",
      "southAsianCuisine          1\n",
      "Name: second_pop_cuisine_nm, dtype: int64\n",
      "\n",
      "eastAsianCuisine           464\n",
      "southAmericanCuisine       346\n",
      "southernEuroCuisine        220\n",
      "northAmericanCuisine       172\n",
      "caribbeanCuisine           155\n",
      "southEastAsianCuisine       17\n",
      "centralEuroCuisine           8\n",
      "westernEuroCuisine           7\n",
      "westAsianCuisine             2\n",
      "eastNorthernEuroCuisine      2\n",
      "southAsianCuisine            1\n",
      "Name: third_pop_cuisine_nm, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(locationsSampleStatsDF['most_pop_cuisine_nm'].value_counts(),   end=\"\\n\\n\")\n",
    "print(locationsSampleStatsDF['second_pop_cuisine_nm'].value_counts(), end=\"\\n\\n\")\n",
    "print(locationsSampleStatsDF['third_pop_cuisine_nm'].value_counts(),  end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=calibri size=3, color ='brown'>\n",
    "\n",
    "I observe for from above distribution that 3rd Choice of cuisnes 'eastNorthernEuroCuisine', 'westAsianCuisine', 'southAsianCuisine' has very few regions there fore I remove them from analysis. Classifications algorithms with very sparse target variable may not work well\n",
    "\n",
    "### <font color = brown><i>  Data Cleansing & Preprocessing </i> </font> <a name=\"cleansing\"></a>\n",
    "\n",
    "* Removing Inconsisten Values\n",
    "   It is observed in US census data NUll values are denoted by -666666666, therefore removing those values by null for\n",
    "<br><br>\n",
    "* Replacing NaN values wirh Median, Since Median is better representation of population data and is unaffected by extreme    values.\n",
    "<br><br>\n",
    "* Scaling and doing data normalization of Numeric values\n",
    "\n",
    "<br>\n",
    "\n",
    "[Back To ToC](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eastAsianCuisine         464\n",
      "southAmericanCuisine     346\n",
      "southernEuroCuisine      220\n",
      "northAmericanCuisine     172\n",
      "caribbeanCuisine         155\n",
      "southEastAsianCuisine     17\n",
      "centralEuroCuisine         8\n",
      "westernEuroCuisine         7\n",
      "Name: third_pop_cuisine_nm, dtype: int64\n",
      "\n",
      "Total Num of rows in Filtered Sample file ............= 1389 \n"
     ]
    }
   ],
   "source": [
    "locationsSampleStatsDF = locationsSampleStatsDF[(locationsSampleStatsDF.third_pop_cuisine_nm != 'eastNorthernEuroCuisine') &\n",
    "                            (locationsSampleStatsDF.third_pop_cuisine_nm != 'westAsianCuisine')   &\n",
    "                            (locationsSampleStatsDF.third_pop_cuisine_nm != 'southAsianCuisine')]\n",
    "\n",
    "print(locationsSampleStatsDF['third_pop_cuisine_nm'].value_counts(),  end=\"\\n\\n\")\n",
    "print('Total Num of rows in Filtered Sample file ............= {} '.format(locationsSampleStatsDF.shape[0] ) )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locationsSampleStatsDF.replace(-666666666, np.nan,inplace=True)\n",
    "locationsSampleStatsDF['region_cnt'] = locationsSampleStatsDF['region_cnt'].astype(float) \n",
    "\n",
    "ints     = ['int64']\n",
    "intDF    = locationsSampleStatsDF.select_dtypes(include=ints)\n",
    "\n",
    "categ     = ['object']\n",
    "categDF   = locationsSampleStatsDF.select_dtypes(include=categ)\n",
    "type(categDF)\n",
    "########################################################################################################################################################\n",
    "###\n",
    "### Performing  Data normalization for Numeric Features\n",
    "###\n",
    "########################################################################################################################################################\n",
    "floats  = ['float64']\n",
    "floatDF = locationsSampleStatsDF.select_dtypes(include=floats)\n",
    "\n",
    "floatDF  = floatDF.fillna(floatDF.median())\n",
    "\n",
    "floatDF  = floatDF.apply(lambda x : (x - x.mean()) / (x.std() )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics          import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection  import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.svm              import SVC\n",
    "from sklearn.naive_bayes      import GaussianNB\n",
    "from xgboost                  import XGBClassifier\n",
    "from sklearn.neighbors        import KNeighborsClassifier\n",
    "from sklearn.tree             import DecisionTreeClassifier\n",
    "from sklearn.ensemble         import RandomForestClassifier \n",
    "\n",
    "from sklearn.pipeline         import Pipeline\n",
    "from sklearn                  import metrics\n",
    "\n",
    "from sklearn                  import preprocessing\n",
    "from collections              import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### I am adding locationName so that I can map them later for accuracy\n",
    "x     = pd.concat([categDF['locationsName'],floatDF], axis=1)\n",
    "\n",
    "y_clf = categDF[['third_pop_cuisine_nm']]    ## Target Variable for Predicting Preferred Cuisine \n",
    "y_reg = intDF[['third_pop_cuisine_cnt']]     ## Target Variable for Predicting How many restaurants can support in the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(972, 57)\n",
      "(972, 1)\n",
      "\n",
      "Resampled Dataset Targert variable dist.............-> : \n",
      "Counter({2: 324, 4: 242, 6: 158, 3: 119, 0: 109, 5: 10, 7: 6, 1: 4})\n",
      "\n",
      "Resampled Dataset Targert variable dist.............-> : \n",
      "Counter({2: 140, 4: 104, 6: 62, 3: 53, 0: 46, 5: 7, 1: 4, 7: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "### Creating training and testing sets for Classification\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y_clf, test_size=.3, random_state=21)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_train_locationNames = x_train['locationsName']\n",
    "x_test_locationNames  = x_test['locationsName']\n",
    "\n",
    "x_train = x_train.drop('locationsName',1)\n",
    "x_test  = x_test.drop('locationsName',1)\n",
    "\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "x_test= x_test.values\n",
    "y_test= y_test.values.ravel()\n",
    "\n",
    "\n",
    "##########################################################################################################################\n",
    "# Transforming non numerical labels into numerical labels\n",
    "##########################################################################################################################\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# encoding train and test labels \n",
    "y_clf_encoded   = encoder.fit_transform(y_clf)\n",
    "y_train_encoded = encoder.transform(y_train)\n",
    "y_test_encoded  = encoder.transform(y_test)\n",
    "\n",
    "print(\"\\nResampled Dataset Targert variable dist.............-> : \\n{}\".format(Counter(y_train_encoded)))  \n",
    "print(\"\\nResampled Dataset Targert variable dist.............-> : \\n{}\".format(Counter(y_test_encoded)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_scoring='recall_micro'\n",
    "v_cv     = 4\n",
    "v_verbose= 1\n",
    "jobs     = -1   ### n_jobs = -1 means maximum possible available\n",
    "##########################################################################################################################\n",
    "### \n",
    "### Model 1 : Decision Tree Classifier\n",
    "###\n",
    "##########################################################################################################################\n",
    "# Set grid search params\n",
    "grid_params = {'dt_clf__criterion'         : [\"gini\", \"entropy\"],\n",
    "                'dt_clf__min_samples_split': [2,3,5],\n",
    "                'dt_clf__max_depth'        : [None,15,20,25] , \n",
    "                'dt_clf__min_samples_leaf' : [1,5, 10, 20],\n",
    "                'dt_clf__max_leaf_nodes'   : [None, 5, 10, 20]}\n",
    "\n",
    "# Construct pipeline\n",
    "pipe = Pipeline([('dt_clf', DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "# Construct grid search\n",
    "gs_dt = GridSearchCV(estimator=pipe, param_grid=grid_params, scoring=v_scoring ,cv=v_cv, verbose=v_verbose, n_jobs=jobs)\n",
    "##########################################################################################################################\n",
    "### \n",
    "### Model 2 : Random Forest Classifier\n",
    "###\n",
    "##########################################################################################################################\n",
    "# Set grid search params                              \n",
    "grid_params = [{'rf_clf__max_features'     : ['auto','sqrt'],\n",
    "                'rf_clf__n_estimators'     : [1,10,20,50],               \n",
    "                'rf_clf__min_samples_leaf' : [1,10,50],\n",
    "                'rf_clf__max_depth'        : [5,10,20],        \n",
    "                'rf_clf__min_samples_split': [2,4,8],\n",
    "                'rf_clf__max_leaf_nodes'   : [10, 20]}]\n",
    "\n",
    "# Construct pipeline\n",
    "pipe = Pipeline([('rf_clf', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "# Construct grid search\n",
    "gs_rf = GridSearchCV(estimator=pipe, param_grid=grid_params, scoring=v_scoring ,cv=v_cv, verbose=v_verbose, n_jobs=jobs)\n",
    "\n",
    "##########################################################################################################################\n",
    "### \n",
    "### Model 3 :  Support Vector Machines Classifier\n",
    "###\n",
    "##########################################################################################################################\n",
    "# Set grid search params\n",
    "param_range = [5,10,15,20]\n",
    "grid_params = [{'svm_clf__kernel': ['linear', 'rbf'], \n",
    "                'svm_clf__C'     : [2, 4, 6, 8, 10],\n",
    "                'svm_clf__gamma' : ['auto'] }]\n",
    "              \n",
    "# Construct pipeline\n",
    "pipe = Pipeline([('svm_clf', SVC(random_state=42, probability = True))])\n",
    "\n",
    "# Construct grid search\n",
    "gs_svm = GridSearchCV(estimator=pipe, param_grid=grid_params, scoring=v_scoring ,cv=v_cv, verbose=v_verbose,n_jobs=jobs)\n",
    "\n",
    "##########################################################################################################################\n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_dt,\n",
    "         gs_rf, \n",
    "         gs_svm]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {0: 'DT -Decision-Tree',\n",
    "             1: 'RF -Random-Forst',\n",
    "             2: 'SVM-Support-Vector-Machine'}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimator: Decision-Tree\n",
      "Fitting 4 folds for each of 384 candidates, totalling 1536 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1536 out of 1536 | elapsed:   24.0s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Recall..............-> : 0.401\n",
      "Test Data Accuracy ......-> 0.434052757793765\n",
      "\n",
      "\n",
      "[[ 22   0  17   0   7   0   0   0]\n",
      " [  2   0   2   0   0   0   0   0]\n",
      " [  6   0 133   0   1   0   0   0]\n",
      " [  5   0  25   0  23   0   0   0]\n",
      " [ 14   0  64   0  26   0   0   0]\n",
      " [  1   0   6   0   0   0   0   0]\n",
      " [  2   0  60   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0]]\n",
      "\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     caribbeanCuisine       0.42      0.48      0.44        46\n",
      "   centralEuroCuisine       0.00      0.00      0.00         4\n",
      "     eastAsianCuisine       0.43      0.95      0.60       140\n",
      " northAmericanCuisine       0.00      0.00      0.00        53\n",
      " southAmericanCuisine       0.46      0.25      0.32       104\n",
      "southEastAsianCuisine       0.00      0.00      0.00         7\n",
      "  southernEuroCuisine       0.00      0.00      0.00        62\n",
      "   westernEuroCuisine       0.00      0.00      0.00         1\n",
      "\n",
      "          avg / total       0.30      0.43      0.33       417\n",
      "\n",
      "\n",
      "Estimator: Random-Forst\n",
      "Fitting 4 folds for each of 432 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 898 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed:   45.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Recall..............-> : 0.386\n",
      "Test Data Accuracy ......-> 0.4028776978417266\n",
      "\n",
      "\n",
      "[[  6   0  23   1  16   0   0   0]\n",
      " [  0   0   3   0   1   0   0   0]\n",
      " [  3   0 123   0  14   0   0   0]\n",
      " [ 10   0  21   1  18   0   3   0]\n",
      " [  3   0  64   0  37   0   0   0]\n",
      " [  0   0   6   0   1   0   0   0]\n",
      " [  2   0  57   0   2   0   1   0]\n",
      " [  0   0   1   0   0   0   0   0]]\n",
      "\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     caribbeanCuisine       0.25      0.13      0.17        46\n",
      "   centralEuroCuisine       0.00      0.00      0.00         4\n",
      "     eastAsianCuisine       0.41      0.88      0.56       140\n",
      " northAmericanCuisine       0.50      0.02      0.04        53\n",
      " southAmericanCuisine       0.42      0.36      0.38       104\n",
      "southEastAsianCuisine       0.00      0.00      0.00         7\n",
      "  southernEuroCuisine       0.25      0.02      0.03        62\n",
      "   westernEuroCuisine       0.00      0.00      0.00         1\n",
      "\n",
      "          avg / total       0.37      0.40      0.31       417\n",
      "\n",
      "\n",
      "Estimator: Support-Vector-Machine\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   16.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Recall..............-> : 0.388\n",
      "Test Data Accuracy ......-> 0.434052757793765\n",
      "\n",
      "\n",
      "[[ 10   0  12   0  24   0   0   0]\n",
      " [  1   0   2   0   1   0   0   0]\n",
      " [  4   0 121   0  15   0   0   0]\n",
      " [  8   0  19   4  22   0   0   0]\n",
      " [  7   0  51   0  46   0   0   0]\n",
      " [  0   0   6   0   1   0   0   0]\n",
      " [  1   0  55   0   6   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0]]\n",
      "\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "     caribbeanCuisine       0.32      0.22      0.26        46\n",
      "   centralEuroCuisine       0.00      0.00      0.00         4\n",
      "     eastAsianCuisine       0.45      0.86      0.59       140\n",
      " northAmericanCuisine       1.00      0.08      0.14        53\n",
      " southAmericanCuisine       0.40      0.44      0.42       104\n",
      "southEastAsianCuisine       0.00      0.00      0.00         7\n",
      "  southernEuroCuisine       0.00      0.00      0.00        62\n",
      "   westernEuroCuisine       0.00      0.00      0.00         1\n",
      "\n",
      "          avg / total       0.41      0.43      0.35       417\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "best_clf = 0.0\n",
    "best_gs  = ''\n",
    "\n",
    "for idx, gsm in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx][4:])    \n",
    "    #####################################################################################################\n",
    "    ### Fit training set using grid search    #print(gsm.get_params().keys())\n",
    "    #####################################################################################################\n",
    "    #gsm.fit(x_train_res,y_train_res.ravel())\n",
    "    \n",
    "    gsm.fit(x_train,y_train_encoded)\n",
    "    #####################################################################################################\n",
    "    ### Printing \n",
    "    ###  1. Best score on training set\n",
    "    ###  2. Best params on training set\n",
    "    ###  3. Classification report and Accuracy on test set\n",
    "    #####################################################################################################\n",
    "    # Best Params\n",
    "    #print('Best params..............-> : {}'.format(gsm.best_params_))    \n",
    "\n",
    "    # Best Recall \n",
    "    print('Best Recall..............-> : %.3f' % gsm.best_score_)\n",
    "\n",
    "    # Predicting on Best Model \n",
    "    y_pred = gsm.predict(x_test)\n",
    "    y_pred_label = list(encoder.inverse_transform(y_pred))  \n",
    "                              \n",
    "    # Print Classification Report and Accuracy\n",
    "    print(\"Test Data Accuracy ......-> {}\".format(metrics.accuracy_score(y_test, y_pred_label)))    \n",
    "    print(\"\\n\")    \n",
    "    \n",
    "    print(confusion_matrix(y_test,y_pred_label))    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(classification_report(y_test, y_pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = brown><i> Analysis of Results & Discussion</font></i> <a name=\"results\"></a>\n",
    "<font face=calibri size=3> From the above 3 Machine Learning Models, I can see all 3 classificagtion models are able to predict 'eastAsianCuisine' with good f1-score i.e. more about .60\n",
    "\n",
    "Since Data is highly imbalanced, minority classes tend to be predicted as majority classes. So we might need more data set to find that correctly.\n",
    "\n",
    "\n",
    "Nex stage of analysis is to find the number of Restaurants regions can support on basis of regression. The regions which has maximum potential will be the one which has highest difference between Predicted count and Existing count.\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "</font>\n",
    "[Back To ToC](#ToC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <font color = brown><i> Conclusion & Further Study</font></i> <a name=\"conclusion\"></a>\n",
    "<font face=calibri size=3> \n",
    "<br/><br/>\n",
    "\n",
    "In this study I hypothesized how Demographic information of regions and along with exisiting restautants, we can go about finding what type of Cusisine and what number of additional restaurants can be set in a regions as defined by US census.\n",
    "\n",
    "\n",
    "Due to limits on API usage I could do this analysis on limited amount of Data. But would do this study on larger dataset and predicti What is the maximum revenue one can derive by setting restaurant in each region.\n",
    "\n",
    "<br/>\n",
    "\n",
    "This conclides this submission the project. \n",
    "\n",
    "</font>\n",
    "[Back To ToC](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
